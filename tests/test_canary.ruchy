// test_canary.ruchy â€” Golden output regression tests
//
// Verifies that apr inference produces text matching the oracle golden outputs.
// This is the most important test: catches inference regressions immediately.

import std::fs
import std::process

// --- Helpers (ruchy has no file imports, must be inline) ---

fun run_apr(args) {
    let (stdout, stderr, code) = process::execute("apr", args)?
    if code != 0 { return Err(f"apr failed ({code}): {stderr}") }
    Ok(stdout)
}

fun apr_run_json(model_path, prompt) {
    let stdout = run_apr(["run", model_path, "-p", prompt, "-n", "32", "--json"])?
    Ok(parse_json(stdout))
}

fun load_oracle(slug, prompt_name) {
    let text = fs::read_to_string(f"oracle/{slug}/{prompt_name}.json")?
    Ok(parse_json(text))
}

// --- Model + prompt configuration ---

let MODELS = [
    { slug: "smollm-135m", int4: "models/smollm-135m-int4.apr", int8: "models/smollm-135m-int8.apr" },
    { slug: "qwen2-0.5b",  int4: "models/qwen2-0.5b-int4.apr",  int8: "models/qwen2-0.5b-int8.apr" },
    { slug: "gpt2-124m",   int4: "models/gpt2-124m-int4.apr",   int8: "models/gpt2-124m-int8.apr" },
]

let PROMPTS = ["arithmetic", "completion", "code", "greeting"]

// --- Tests ---

@test
fun test_canary_int8_smollm_arithmetic() {
    let oracle = load_oracle("smollm-135m", "arithmetic")?
    let result = apr_run_json("models/smollm-135m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"SmolLM Int8 arithmetic canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_smollm_completion() {
    let oracle = load_oracle("smollm-135m", "completion")?
    let result = apr_run_json("models/smollm-135m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"SmolLM Int8 completion canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_smollm_code() {
    let oracle = load_oracle("smollm-135m", "code")?
    let result = apr_run_json("models/smollm-135m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"SmolLM Int8 code canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_smollm_greeting() {
    let oracle = load_oracle("smollm-135m", "greeting")?
    let result = apr_run_json("models/smollm-135m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"SmolLM Int8 greeting canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_qwen2_arithmetic() {
    let oracle = load_oracle("qwen2-0.5b", "arithmetic")?
    let result = apr_run_json("models/qwen2-0.5b-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"Qwen2 Int8 arithmetic canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_qwen2_completion() {
    let oracle = load_oracle("qwen2-0.5b", "completion")?
    let result = apr_run_json("models/qwen2-0.5b-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"Qwen2 Int8 completion canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_qwen2_code() {
    let oracle = load_oracle("qwen2-0.5b", "code")?
    let result = apr_run_json("models/qwen2-0.5b-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"Qwen2 Int8 code canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_qwen2_greeting() {
    let oracle = load_oracle("qwen2-0.5b", "greeting")?
    let result = apr_run_json("models/qwen2-0.5b-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"Qwen2 Int8 greeting canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_gpt2_arithmetic() {
    let oracle = load_oracle("gpt2-124m", "arithmetic")?
    let result = apr_run_json("models/gpt2-124m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"GPT-2 Int8 arithmetic canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_gpt2_completion() {
    let oracle = load_oracle("gpt2-124m", "completion")?
    let result = apr_run_json("models/gpt2-124m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"GPT-2 Int8 completion canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_gpt2_code() {
    let oracle = load_oracle("gpt2-124m", "code")?
    let result = apr_run_json("models/gpt2-124m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"GPT-2 Int8 code canary mismatch: got '{result.text}', expected '{oracle.text}'")
}

@test
fun test_canary_int8_gpt2_greeting() {
    let oracle = load_oracle("gpt2-124m", "greeting")?
    let result = apr_run_json("models/gpt2-124m-int8.apr", oracle.prompt)?
    assert_eq(result.text, oracle.text, f"GPT-2 Int8 greeting canary mismatch: got '{result.text}', expected '{oracle.text}'")
}
